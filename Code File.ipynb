{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b52313",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, plot_confusion_matrix, plot_roc_curve\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pandas\n",
    "#!pip install --upgrade scikit-learn numpy\n",
    "!pip install --upgrade scikit-learn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imblearn\n",
    "from sklearn.metrics import accuracy_score, classification_report, plot_confusion_matrix, plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e69453",
   "metadata": {},
   "source": [
    "# Load the Swarm Behaviour Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b686ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_df= pd.read_csv(\"F:\\cse445Project\\Swarm_Behaviour.csv\\Swarm_Behaviour.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57034b7",
   "metadata": {},
   "source": [
    "# Display basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swarm_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d620d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe5f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f2b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(swarm_df[\"Swarm_Behaviour\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e29c9e",
   "metadata": {},
   "source": [
    "# accuracy w/o using SMOTE technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f133118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate class count\n",
    "class_0 = swarm_df[swarm_df[\"Swarm_Behaviour\"]==0]\n",
    "class_1 = swarm_df[swarm_df[\"Swarm_Behaviour\"]==1]\n",
    "#print the shape of the class\n",
    "print('Class 0:', class_0.shape)\n",
    "print('Class 1:', class_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca659f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = swarm_df.drop(columns = [\"Swarm_Behaviour\"])\n",
    "Y= swarm_df[\"Swarm_Behaviour\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, stratify = Y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff18204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using knn algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train,Y_train)\n",
    "predictions= knn.predict(X_test)\n",
    "try:\n",
    "    predictions = knn.predict(X_test)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "print('Train Accuracy',\"{:.3f}\".format(accuracy_score(Y_train,knn.predict(X_train))))\n",
    "print('Test Accuracy',\"{:3f}\".format(accuracy_score(Y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd3b25",
   "metadata": {},
   "source": [
    "# to deal with the imbalanced dataset : SMOTE technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6eacf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "smote = SMOTE()\n",
    "#fit predictor & target variable \n",
    "x_smote, y_smote = smote.fit_resample(X,Y)\n",
    "print (\"Original Dataset Shape:\", Counter(Y))\n",
    "print (\"Resample Dataset Shape\", Counter(y_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0d2ca",
   "metadata": {},
   "source": [
    "accuracy after applying SMOTE technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using knn algorithm\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_smote, y_smote, test_size=0.3,random_state=2)\n",
    "knn.fit(X_train,Y_train)\n",
    "predictions= knn.predict(X_test)\n",
    "print('Train Accuracy',\"{:.3f}\".format(accuracy_score(Y_train,knn.predict(X_train))))\n",
    "print('Test Accuracy',\"{:3f}\".format(accuracy_score(Y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9266f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Apply Pandas Profiling\n",
    "#!pip install ydata_profiling\n",
    "#from ydata_profiling import ProfileReport\n",
    "#from pandas_profiling import ydata_profiling\n",
    "#prof = ProfileReport(swarm_df.sample(n=1000))   # Sample 1000 random rows\n",
    "#prof.to_file(output_file='Swarm Behaviour Classification.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing (e.g, data cleaning )\n",
    "#***code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9954f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general structure for different model's accuracy prediction \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import scikitplot as skplt\n",
    "def Results(clf): \n",
    "    clf.fit(X_train, Y_train)\n",
    "    predictions= clf.predict(X_test)\n",
    "    print(clf)\n",
    "    print('Train Accuracy',\"{:.3f}\".format(accuracy_score(Y_train,clf.predict(X_train)))) \n",
    "    print('Test Accuracy',\"{:3f}\".format(accuracy_score(Y_test,predictions)))\n",
    "    print(classification_report(Y_test, predictions)) \n",
    "    print(confusion_matrix(Y_test, predictions))\n",
    "    #skplt.metrics.plot_confusion_matrix(Y_test, predictions); \n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e57201",
   "metadata": {},
   "source": [
    "Building models for different classification models using the general structure-\n",
    "1.Logistic Regression\n",
    "2.Decision Trees\n",
    "3.Random Forest\n",
    "4.Support Vector Machines (SVM)\n",
    "5.k-Nearest Neighbors (k-NN)\n",
    "6.Naive Bayes\n",
    "7.Gradient Boosting Algorithms (e.g., XGBoost, LightGBM, AdaBoost)\n",
    "8.Linear Discriminant Analysis (LDA)\n",
    "9.Quadratic Discriminant Analysis (QDA)\n",
    "10.Gaussian Processes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e597bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building models for different classification models using the general structure\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "lr= LogisticRegression()\n",
    "\n",
    "dt= DecisionTreeClassifier()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "svm= SVC()\n",
    "\n",
    "knn= KNeighborsClassifier()\n",
    "\n",
    "xg=xgb.XGBClassifier()\n",
    "\n",
    "LDA= LinearDiscriminantAnalysis()\n",
    "QDA=QuadraticDiscriminantAnalysis()\n",
    "\n",
    "classifiers=[lr,dt,rf,svm,knn,xg,LDA,QDA]\n",
    "\n",
    "for clf in classifiers:\n",
    "    Results(clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5968d3",
   "metadata": {},
   "source": [
    "--> we will use this / other hyperparameter tuning tech to the best model \n",
    "lr1=LogisticRegression( C=0.01, solver='liblinear',max_iter=10)\n",
    "dt1 = DecisionTreeClassifier( criterion='gini',max_depth=None, min_samples_split=5,min_samples_leaf=1,max_features=None)\n",
    "rf1 = RandomForestClassifier( n_estimators=7, criterion='entropy',max_depth=None,min_samples_split=5,min_samples_leaf=1, max_features='auto')\n",
    "svm1= SVC(C=1.0,kernel='rbf',gamma='scale')\n",
    "knn1= KNeighborsClassifier( n_neighbors=5,weights='uniform', algorithm='auto', p=2)\n",
    "xg1=xgb.XGBClassifier(learning_rate=0.1,n_estimators=10,max_depth=6,min_child_weight=1,subsample=0.7)\n",
    "gp1=GaussianProcessClassifier(kernel=1.0 * RBF(1.0),n_restarts_optimizer=10,max_iter_predict=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d553637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
